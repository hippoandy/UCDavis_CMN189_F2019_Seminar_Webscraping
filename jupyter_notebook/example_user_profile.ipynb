{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Demo - User Profile\n",
    "\n",
    "#### Author: Yu-Chang Ho (Andy), UC Davis\n",
    "#### Latest Update: 2019 10/13\n",
    "\n",
    "\n",
    "This notebook demonstrates the basic implementation for scraping data using BeautifulSoup4 library. Please use the website [https://hipposerver.ddns.net/webscraping/](https://hipposerver.ddns.net/webscraping/) as the sample webpage to practice webscraping.\n",
    "\n",
    "- Target website: [https://hipposerver.ddns.net/webscraping/](https://hipposerver.ddns.net/webscraping/)\n",
    "- Objective: Get a user profile data in a clean CSV format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Retrieve the webpage source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<meta charset=\"utf-8\">\n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
      "\n",
      "<title>Web-scraping Demo - User Profile Example</title>\n",
      "\n",
      "<script src=\"assets/js/syntax_highlight.js\"></script>\n",
      "\n",
      "<style>\n",
      "body {\n",
      "    font-size: 1.5em;\n",
      "}\n",
      "\n",
      ".bold-text {\n",
      "    font-weight: bold;    \n",
      "}\n",
      "</style>\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "    <h1>User Profile Example</h1>\n",
      "    <hr />\n",
      "    <div class=\"freelancer\">\n",
      "        <div id=\"name\">Andy Ho</div>\n",
      "        <div id=\"location\">Davis, CA, USA</div>\n",
      "        <div class=\"bold-text\">$50/hr</div>\n",
      "        <div class=\"experience\">1.5 years</div>\n",
      "        <div class=\"rating\" data=\"5.0\">Excellent</div>\n",
      "        <div class=\"domain\">Software</div>\n",
      "    </div>\n",
      "\n",
      "    <!-- ********** IGNORE THE BELOW PART!! ********** -->\n",
      "\n",
      "    <pre id=\"code\">\n",
      "        &lt;div class=\"freelancer\"&gt;\n",
      "            &lt;div id=\"name\"&gt;Andy Ho&lt;/div&gt;\n",
      "            &lt;div id=\"location\"&gt;Davis, CA, USA&lt;/div&gt;\n",
      "            &lt;div class=\"bold-text\"&gt;$50/hr&lt;/div&gt;\n",
      "            &lt;div class=\"experience\"&gt;1.5 years&lt;/div&gt;\n",
      "            &lt;div class=\"rating\" data=\"5.0\"&gt;Excellent&lt;/div&gt;\n",
      "            &lt;div class=\"domain\"&gt;Software&lt;/div&gt;\n",
      "        &lt;/div&gt;\n",
      "    </pre>\n",
      "</body>\n",
      "<script>\n",
      "w3CodeColor( document.getElementById( \"code\" ) );\n",
      "</script>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "### connect to the server and get the content of the webpage\n",
    "\n",
    "url = 'https://hipposerver.ddns.net/webscraping/'\n",
    "\n",
    "# get the source code of the webpage\n",
    "r = requests.get( url )\n",
    "# check it out!\n",
    "print( r.text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Create a BeautifulSoup4 Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a Beautiful Soup parser\n",
    "'''\n",
    "normally, we use 'html.parser' as the default parser\n",
    "but, many user suggest to use 'html5lib'\n",
    "'''\n",
    "soup = BeautifulSoup( r.text, 'html.parser' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Locate the Target Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"freelancer\">\n",
      "<div id=\"name\">Andy Ho</div>\n",
      "<div id=\"location\">Davis, CA, USA</div>\n",
      "<div class=\"bold-text\">$50/hr</div>\n",
      "<div class=\"experience\">1.5 years</div>\n",
      "<div class=\"rating\" data=\"5.0\">Excellent</div>\n",
      "<div class=\"domain\">Software</div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "### search for a specific element\n",
    "# search a div element\n",
    "e = soup.find( 'div' )\n",
    "print( e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"bold-text\">$50/hr</div>\n"
     ]
    }
   ],
   "source": [
    "# search an element by a specific class name\n",
    "e = soup.find( 'div', class_='bold-text' )\n",
    "print( e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"name\">Andy Ho</div>\n"
     ]
    }
   ],
   "source": [
    "# search an element by a specific id\n",
    "e = soup.find( 'div', { \"id\": \"name\" } )\n",
    "print( e )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall the HTML Structure\n",
    "\n",
    "```html\n",
    "<div class=\"freelancer\">\n",
    "    <div id=\"name\">Andy Ho</div>\n",
    "    <div id=\"location\">Davis, CA, USA</div>\n",
    "    <div class=\"bold-text\">$50/hr</div>\n",
    "    <div class=\"experience\">1.5 years</div>\n",
    "    <div class=\"domain\">Software</div>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.1:\t<div class=\"freelancer\">\n",
      "<div id=\"name\">Andy Ho</div>\n",
      "<div id=\"location\">Davis, CA, USA</div>\n",
      "<div class=\"bold-text\">$50/hr</div>\n",
      "<div class=\"experience\">1.5 years</div>\n",
      "<div class=\"rating\" data=\"5.0\">Excellent</div>\n",
      "<div class=\"domain\">Software</div>\n",
      "</div>\n",
      "No.2:\t<div id=\"name\">Andy Ho</div>\n",
      "No.3:\t<div id=\"location\">Davis, CA, USA</div>\n",
      "No.4:\t<div class=\"bold-text\">$50/hr</div>\n",
      "No.5:\t<div class=\"experience\">1.5 years</div>\n",
      "No.6:\t<div class=\"rating\" data=\"5.0\">Excellent</div>\n",
      "No.7:\t<div class=\"domain\">Software</div>\n"
     ]
    }
   ],
   "source": [
    "### search for multiple element\n",
    "idx = 0\n",
    "for e in soup.find_all( 'div' ):\n",
    "    idx += 1\n",
    "    print( f\"No.{idx}:\\t\" + str(e) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the elements under a parent element\n",
    "\n",
    "In the above code, we have a line:\n",
    "\n",
    "`soup = BeautifulSoup( r.text, 'html.parser' )`,\n",
    "\n",
    "which makes the variable `soup` holds all the content of a webpage.\n",
    "\n",
    "later, we use `soup.find()` to find a certain element.\n",
    "\n",
    "If we want to further find a sub-element under a retrieved element, we could do the same!\n",
    "\n",
    "### Recall the HTML Structure\n",
    "\n",
    "```html\n",
    "<div class=\"freelancer\">\n",
    "    <div id=\"name\">Andy Ho</div>\n",
    "    <div id=\"location\">Davis, CA, USA</div>\n",
    "    <div class=\"bold-text\">$50/hr</div>\n",
    "    <div class=\"experience\">1.5 years</div>\n",
    "    <div class=\"domain\">Software</div>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div id=\"name\">Andy Ho</div>\n"
     ]
    }
   ],
   "source": [
    "### Assuming we want to find the elements under <div class=\"freelancer\">\n",
    "# 1. get the parent\n",
    "parent = soup.find( 'div', class_='freelancer' )\n",
    "\n",
    "# 2. call the find() funct using the located element\n",
    "name = parent.find( 'div', { \"id\": \"name\" } )\n",
    "print( name )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Get the Value We Want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andy Ho\n"
     ]
    }
   ],
   "source": [
    "### retrieve the value\n",
    "# get the name\n",
    "# the value we want is placed within the element block\n",
    "\n",
    "'''\n",
    "<div id=\"name\">Andy Ho</div>\n",
    "'''\n",
    "\n",
    "e = soup.find( 'div', { \"id\": \"name\" } )\n",
    "print( e.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# get the rating\n",
    "# the value we want is placed in the element attribute\n",
    "\n",
    "'''\n",
    "<div class=\"rating\" data=\"5.0\">Excellent</div>\n",
    "'''\n",
    "\n",
    "e = soup.find( 'div', class_=\"rating\" )\n",
    "print( e[ 'data' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"freelancer\">\n",
      "<div id=\"name\">Andy Ho</div>\n",
      "<div id=\"location\">Davis, CA, USA</div>\n",
      "<div class=\"bold-text\">$50/hr</div>\n",
      "<div class=\"experience\">1.5 years</div>\n",
      "<div class=\"rating\" data=\"5.0\">Excellent</div>\n",
      "<div class=\"domain\">Software</div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "### prepare the output dataframe\n",
    "\n",
    "# 1. find the parent that holds all the elements we want\n",
    "parent = soup.find( 'div', class_='freelancer' )\n",
    "print( parent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andy Ho\n",
      "Davis, CA, USA\n",
      "$50/hr\n",
      "1.5 years\n",
      "5.0\n",
      "Software\n"
     ]
    }
   ],
   "source": [
    "# 2. retrive the data\n",
    "name   = parent.find( 'div', { 'id': 'name' } ).text\n",
    "loc    = parent.find( 'div', { 'id': 'location' } ).text\n",
    "salary = parent.find( 'div', class_='bold-text' ).text\n",
    "exp    = parent.find( 'div', class_='experience' ).text\n",
    "rating = parent.find( 'div', class_='rating' )[ \"data\" ]\n",
    "domain = parent.find( 'div', class_='domain' ).text\n",
    "\n",
    "print( name )\n",
    "print( loc )\n",
    "print( salary )\n",
    "print( exp )\n",
    "print( rating )\n",
    "print( domain )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. data cleaning and transformation\n",
    "parts = str(loc).split( \", \" )\n",
    "city = parts[ 0 ]\n",
    "state = parts[ 1 ]\n",
    "country = parts[ 2 ]\n",
    "\n",
    "exp = float(str(exp).replace( \" years\", \"\" ))\n",
    "\n",
    "rating = float(str(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Andy Ho', 'Davis', 'CA', 'USA', '$50/hr', 1.5, 5.0, 'Software']\n"
     ]
    }
   ],
   "source": [
    "# 4. append the data as a row\n",
    "row = []\n",
    "row.append( name )\n",
    "row.append( city )\n",
    "row.append( state )\n",
    "row.append( country )\n",
    "row.append( salary )\n",
    "row.append( exp )\n",
    "row.append( rating )\n",
    "row.append( domain )\n",
    "\n",
    "print( row )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. create a dataframe and append the data row\n",
    "header = [ \"name\", \"city\", \"state\", \"country\", \"expected_salary\", \"experience\", \"rating\", \"domain\" ]\n",
    "df = pd.DataFrame( [row], columns=header )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name   city state country expected_salary  experience  rating    domain\n",
      "0  Andy Ho  Davis    CA     USA          $50/hr         1.5     5.0  Software\n"
     ]
    }
   ],
   "source": [
    "# 6. the result\n",
    "print( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
